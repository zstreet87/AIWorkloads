model_framework:
  type: "huggingface"
  requirements:
    - transformers
    - datasets
    - torch
  env_vars:
    HF_DATASETS_CACHE: "/mnt/shared/datasets_cache"
  job_scheduler:
    type: "slurm" # or "k8" for Kubernetes
    slurm:
      env_vars:
        SLURM_PROCID: "0"
        WORLD_SIZE: "1"
        GPUS_PER_NODE: "1"
    k8:
      env_vars:
        K8_NODE_RANK: "0"
        K8_NUM_NODES: "1"
  cmd: "bash"
  runner: "workload.sh"
  script: "hf.py"
  model_name: "bert-base-uncased"
  task: "text-classification"
  learning_rate: 5e-5
  batch_size: 16
  num_epochs: 3
  training:
    dataset_name: "glue"
    dataset_config_name: "mrpc"
    batch_size: 16
    num_epochs: 3
    learning_rate: 5e-5
  environment:
    use_gpu: true
    num_gpus: 1
  additional_args: ""
